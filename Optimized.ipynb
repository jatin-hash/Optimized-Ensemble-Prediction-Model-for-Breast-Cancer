{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M       17.990         10.38          122.80     1001.0   \n",
       "1      842517         M       20.570         17.77          132.90     1326.0   \n",
       "2    84300903         M       19.690         21.25          130.00     1203.0   \n",
       "3    84348301         M       11.420         20.38           77.58      386.1   \n",
       "4    84358402         M       20.290         14.34          135.10     1297.0   \n",
       "5      843786         M       12.450         15.70           82.57      477.1   \n",
       "6      844359         M       18.250         19.98          119.60     1040.0   \n",
       "7    84458202         M       13.710         20.83           90.20      577.9   \n",
       "8      844981         M       13.000         21.82           87.50      519.8   \n",
       "9    84501001         M       12.460         24.04           83.97      475.9   \n",
       "10     845636         M       16.020         23.24          102.70      797.8   \n",
       "11   84610002         M       15.780         17.89          103.60      781.0   \n",
       "12     846226         M       19.170         24.80          132.40     1123.0   \n",
       "13     846381         M       15.850         23.95          103.70      782.7   \n",
       "14   84667401         M       13.730         22.61           93.60      578.3   \n",
       "15   84799002         M       14.540         27.54           96.73      658.8   \n",
       "16     848406         M       14.680         20.13           94.74      684.5   \n",
       "17   84862001         M       16.130         20.68          108.10      798.8   \n",
       "18     849014         M       19.810         22.15          130.00     1260.0   \n",
       "19    8510426         B       13.540         14.36           87.46      566.3   \n",
       "20    8510653         B       13.080         15.71           85.63      520.0   \n",
       "21    8510824         B        9.504         12.44           60.34      273.9   \n",
       "22    8511133         M       15.340         14.26          102.50      704.4   \n",
       "23     851509         M       21.160         23.04          137.20     1404.0   \n",
       "24     852552         M       16.650         21.38          110.00      904.6   \n",
       "25     852631         M       17.140         16.40          116.00      912.7   \n",
       "26     852763         M       14.580         21.53           97.41      644.8   \n",
       "27     852781         M       18.610         20.25          122.10     1094.0   \n",
       "28     852973         M       15.300         25.27          102.40      732.4   \n",
       "29     853201         M       17.570         15.05          115.00      955.1   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "539    921362         B        7.691         25.44           48.34      170.4   \n",
       "540    921385         B       11.540         14.44           74.65      402.9   \n",
       "541    921386         B       14.470         24.99           95.81      656.4   \n",
       "542    921644         B       14.740         25.42           94.70      668.6   \n",
       "543    922296         B       13.210         28.06           84.88      538.4   \n",
       "544    922297         B       13.870         20.70           89.77      584.8   \n",
       "545    922576         B       13.620         23.23           87.19      573.2   \n",
       "546    922577         B       10.320         16.35           65.31      324.9   \n",
       "547    922840         B       10.260         16.58           65.85      320.8   \n",
       "548    923169         B        9.683         19.34           61.05      285.7   \n",
       "549    923465         B       10.820         24.21           68.89      361.6   \n",
       "550    923748         B       10.860         21.48           68.51      360.5   \n",
       "551    923780         B       11.130         22.44           71.49      378.4   \n",
       "552    924084         B       12.770         29.43           81.35      507.9   \n",
       "553    924342         B        9.333         21.94           59.01      264.0   \n",
       "554    924632         B       12.880         28.92           82.50      514.3   \n",
       "555    924934         B       10.290         27.61           65.67      321.4   \n",
       "556    924964         B       10.160         19.59           64.73      311.7   \n",
       "557    925236         B        9.423         27.88           59.26      271.3   \n",
       "558    925277         B       14.590         22.68           96.39      657.1   \n",
       "559    925291         B       11.510         23.93           74.52      403.5   \n",
       "560    925292         B       14.050         27.15           91.38      600.4   \n",
       "561    925311         B       11.200         29.37           70.67      386.0   \n",
       "562    925622         M       15.220         30.62          103.40      716.9   \n",
       "563    926125         M       20.920         25.09          143.00     1347.0   \n",
       "564    926424         M       21.560         22.39          142.00     1479.0   \n",
       "565    926682         M       20.130         28.25          131.20     1261.0   \n",
       "566    926954         M       16.600         28.08          108.30      858.1   \n",
       "567    927241         M       20.600         29.33          140.10     1265.0   \n",
       "568     92751         B        7.760         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760        0.300100             0.147100   \n",
       "1            0.08474           0.07864        0.086900             0.070170   \n",
       "2            0.10960           0.15990        0.197400             0.127900   \n",
       "3            0.14250           0.28390        0.241400             0.105200   \n",
       "4            0.10030           0.13280        0.198000             0.104300   \n",
       "5            0.12780           0.17000        0.157800             0.080890   \n",
       "6            0.09463           0.10900        0.112700             0.074000   \n",
       "7            0.11890           0.16450        0.093660             0.059850   \n",
       "8            0.12730           0.19320        0.185900             0.093530   \n",
       "9            0.11860           0.23960        0.227300             0.085430   \n",
       "10           0.08206           0.06669        0.032990             0.033230   \n",
       "11           0.09710           0.12920        0.099540             0.066060   \n",
       "12           0.09740           0.24580        0.206500             0.111800   \n",
       "13           0.08401           0.10020        0.099380             0.053640   \n",
       "14           0.11310           0.22930        0.212800             0.080250   \n",
       "15           0.11390           0.15950        0.163900             0.073640   \n",
       "16           0.09867           0.07200        0.073950             0.052590   \n",
       "17           0.11700           0.20220        0.172200             0.102800   \n",
       "18           0.09831           0.10270        0.147900             0.094980   \n",
       "19           0.09779           0.08129        0.066640             0.047810   \n",
       "20           0.10750           0.12700        0.045680             0.031100   \n",
       "21           0.10240           0.06492        0.029560             0.020760   \n",
       "22           0.10730           0.21350        0.207700             0.097560   \n",
       "23           0.09428           0.10220        0.109700             0.086320   \n",
       "24           0.11210           0.14570        0.152500             0.091700   \n",
       "25           0.11860           0.22760        0.222900             0.140100   \n",
       "26           0.10540           0.18680        0.142500             0.087830   \n",
       "27           0.09440           0.10660        0.149000             0.077310   \n",
       "28           0.10820           0.16970        0.168300             0.087510   \n",
       "29           0.09847           0.11570        0.098750             0.079530   \n",
       "..               ...               ...             ...                  ...   \n",
       "539          0.08668           0.11990        0.092520             0.013640   \n",
       "540          0.09984           0.11200        0.067370             0.025940   \n",
       "541          0.08837           0.12300        0.100900             0.038900   \n",
       "542          0.08275           0.07214        0.041050             0.030270   \n",
       "543          0.08671           0.06877        0.029870             0.032750   \n",
       "544          0.09578           0.10180        0.036880             0.023690   \n",
       "545          0.09246           0.06747        0.029740             0.024430   \n",
       "546          0.09434           0.04994        0.010120             0.005495   \n",
       "547          0.08877           0.08066        0.043580             0.024380   \n",
       "548          0.08491           0.05030        0.023370             0.009615   \n",
       "549          0.08192           0.06602        0.015480             0.008160   \n",
       "550          0.07431           0.04227        0.000000             0.000000   \n",
       "551          0.09566           0.08194        0.048240             0.022570   \n",
       "552          0.08276           0.04234        0.019970             0.014990   \n",
       "553          0.09240           0.05605        0.039960             0.012820   \n",
       "554          0.08123           0.05824        0.061950             0.023430   \n",
       "555          0.09030           0.07658        0.059990             0.027380   \n",
       "556          0.10030           0.07504        0.005025             0.011160   \n",
       "557          0.08123           0.04971        0.000000             0.000000   \n",
       "558          0.08473           0.13300        0.102900             0.037360   \n",
       "559          0.09261           0.10210        0.111200             0.041050   \n",
       "560          0.09929           0.11260        0.044620             0.043040   \n",
       "561          0.07449           0.03558        0.000000             0.000000   \n",
       "562          0.10480           0.20870        0.255000             0.094290   \n",
       "563          0.10990           0.22360        0.317400             0.147400   \n",
       "564          0.11100           0.11590        0.243900             0.138900   \n",
       "565          0.09780           0.10340        0.144000             0.097910   \n",
       "566          0.08455           0.10230        0.092510             0.053020   \n",
       "567          0.11780           0.27700        0.351400             0.152000   \n",
       "568          0.05263           0.04362        0.000000             0.000000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "5    ...          23.75           103.40       741.6           0.17910   \n",
       "6    ...          27.66           153.20      1606.0           0.14420   \n",
       "7    ...          28.14           110.60       897.0           0.16540   \n",
       "8    ...          30.73           106.20       739.3           0.17030   \n",
       "9    ...          40.68            97.65       711.4           0.18530   \n",
       "10   ...          33.88           123.80      1150.0           0.11810   \n",
       "11   ...          27.28           136.50      1299.0           0.13960   \n",
       "12   ...          29.94           151.70      1332.0           0.10370   \n",
       "13   ...          27.66           112.00       876.5           0.11310   \n",
       "14   ...          32.01           108.80       697.7           0.16510   \n",
       "15   ...          37.13           124.10       943.2           0.16780   \n",
       "16   ...          30.88           123.40      1138.0           0.14640   \n",
       "17   ...          31.48           136.80      1315.0           0.17890   \n",
       "18   ...          30.88           186.80      2398.0           0.15120   \n",
       "19   ...          19.26            99.70       711.2           0.14400   \n",
       "20   ...          20.49            96.09       630.5           0.13120   \n",
       "21   ...          15.66            65.13       314.9           0.13240   \n",
       "22   ...          19.08           125.10       980.9           0.13900   \n",
       "23   ...          35.59           188.00      2615.0           0.14010   \n",
       "24   ...          31.56           177.00      2215.0           0.18050   \n",
       "25   ...          21.40           152.40      1461.0           0.15450   \n",
       "26   ...          33.21           122.40       896.9           0.15250   \n",
       "27   ...          27.26           139.90      1403.0           0.13380   \n",
       "28   ...          36.71           149.30      1269.0           0.16410   \n",
       "29   ...          19.52           134.90      1227.0           0.12550   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "539  ...          31.89            54.49       223.6           0.15960   \n",
       "540  ...          19.68            78.78       457.8           0.13450   \n",
       "541  ...          31.73           113.50       808.9           0.13400   \n",
       "542  ...          32.29           107.40       826.4           0.10600   \n",
       "543  ...          37.17            92.48       629.6           0.10720   \n",
       "544  ...          24.75            99.17       688.6           0.12640   \n",
       "545  ...          29.09            97.58       729.8           0.12160   \n",
       "546  ...          21.77            71.12       384.9           0.12850   \n",
       "547  ...          22.04            71.08       357.4           0.14610   \n",
       "548  ...          25.59            69.10       364.2           0.11990   \n",
       "549  ...          31.45            83.90       505.6           0.12040   \n",
       "550  ...          24.77            74.08       412.3           0.10010   \n",
       "551  ...          28.26            77.80       436.6           0.10870   \n",
       "552  ...          36.00            88.10       594.7           0.12340   \n",
       "553  ...          25.05            62.86       295.8           0.11030   \n",
       "554  ...          35.74            88.84       595.7           0.12270   \n",
       "555  ...          34.91            69.57       357.6           0.13840   \n",
       "556  ...          22.88            67.88       347.3           0.12650   \n",
       "557  ...          34.24            66.50       330.6           0.10730   \n",
       "558  ...          27.27           105.90       733.5           0.10260   \n",
       "559  ...          37.16            82.28       474.2           0.12980   \n",
       "560  ...          33.17           100.20       706.7           0.12410   \n",
       "561  ...          38.30            75.19       439.6           0.09267   \n",
       "562  ...          42.79           128.70       915.0           0.14170   \n",
       "563  ...          29.41           179.10      1819.0           0.14070   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560          0.71190               0.26540          0.4601   \n",
       "1              0.18660          0.24160               0.18600          0.2750   \n",
       "2              0.42450          0.45040               0.24300          0.3613   \n",
       "3              0.86630          0.68690               0.25750          0.6638   \n",
       "4              0.20500          0.40000               0.16250          0.2364   \n",
       "5              0.52490          0.53550               0.17410          0.3985   \n",
       "6              0.25760          0.37840               0.19320          0.3063   \n",
       "7              0.36820          0.26780               0.15560          0.3196   \n",
       "8              0.54010          0.53900               0.20600          0.4378   \n",
       "9              1.05800          1.10500               0.22100          0.4366   \n",
       "10             0.15510          0.14590               0.09975          0.2948   \n",
       "11             0.56090          0.39650               0.18100          0.3792   \n",
       "12             0.39030          0.36390               0.17670          0.3176   \n",
       "13             0.19240          0.23220               0.11190          0.2809   \n",
       "14             0.77250          0.69430               0.22080          0.3596   \n",
       "15             0.65770          0.70260               0.17120          0.4218   \n",
       "16             0.18710          0.29140               0.16090          0.3029   \n",
       "17             0.42330          0.47840               0.20730          0.3706   \n",
       "18             0.31500          0.53720               0.23880          0.2768   \n",
       "19             0.17730          0.23900               0.12880          0.2977   \n",
       "20             0.27760          0.18900               0.07283          0.3184   \n",
       "21             0.11480          0.08867               0.06227          0.2450   \n",
       "22             0.59540          0.63050               0.23930          0.4667   \n",
       "23             0.26000          0.31550               0.20090          0.2822   \n",
       "24             0.35780          0.46950               0.20950          0.3613   \n",
       "25             0.39490          0.38530               0.25500          0.4066   \n",
       "26             0.66430          0.55390               0.27010          0.4264   \n",
       "27             0.21170          0.34460               0.14900          0.2341   \n",
       "28             0.61100          0.63350               0.20240          0.4027   \n",
       "29             0.28120          0.24890               0.14560          0.2756   \n",
       "..                 ...              ...                   ...             ...   \n",
       "539            0.30640          0.33930               0.05000          0.2790   \n",
       "540            0.21180          0.17970               0.06918          0.2329   \n",
       "541            0.42020          0.40400               0.12050          0.3187   \n",
       "542            0.13760          0.16110               0.10950          0.2722   \n",
       "543            0.13810          0.10620               0.07958          0.2473   \n",
       "544            0.20370          0.13770               0.06845          0.2249   \n",
       "545            0.15170          0.10490               0.07174          0.2642   \n",
       "546            0.08842          0.04384               0.02381          0.2681   \n",
       "547            0.22460          0.17830               0.08333          0.2691   \n",
       "548            0.09546          0.09350               0.03846          0.2552   \n",
       "549            0.16330          0.06194               0.03264          0.3059   \n",
       "550            0.07348          0.00000               0.00000          0.2458   \n",
       "551            0.17820          0.15640               0.06413          0.3169   \n",
       "552            0.10640          0.08653               0.06498          0.2407   \n",
       "553            0.08298          0.07993               0.02564          0.2435   \n",
       "554            0.16200          0.24390               0.06493          0.2372   \n",
       "555            0.17100          0.20000               0.09127          0.2226   \n",
       "556            0.12000          0.01005               0.02232          0.2262   \n",
       "557            0.07158          0.00000               0.00000          0.2475   \n",
       "558            0.31710          0.36620               0.11050          0.2258   \n",
       "559            0.25170          0.36300               0.09653          0.2112   \n",
       "560            0.22640          0.13260               0.10480          0.2250   \n",
       "561            0.05494          0.00000               0.00000          0.1566   \n",
       "562            0.79170          1.17000               0.23560          0.4089   \n",
       "563            0.41860          0.65990               0.25420          0.2929   \n",
       "564            0.21130          0.41070               0.22160          0.2060   \n",
       "565            0.19220          0.32150               0.16280          0.2572   \n",
       "566            0.30940          0.34030               0.14180          0.2218   \n",
       "567            0.86810          0.93870               0.26500          0.4087   \n",
       "568            0.06444          0.00000               0.00000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "5                    0.12440          NaN  \n",
       "6                    0.08368          NaN  \n",
       "7                    0.11510          NaN  \n",
       "8                    0.10720          NaN  \n",
       "9                    0.20750          NaN  \n",
       "10                   0.08452          NaN  \n",
       "11                   0.10480          NaN  \n",
       "12                   0.10230          NaN  \n",
       "13                   0.06287          NaN  \n",
       "14                   0.14310          NaN  \n",
       "15                   0.13410          NaN  \n",
       "16                   0.08216          NaN  \n",
       "17                   0.11420          NaN  \n",
       "18                   0.07615          NaN  \n",
       "19                   0.07259          NaN  \n",
       "20                   0.08183          NaN  \n",
       "21                   0.07773          NaN  \n",
       "22                   0.09946          NaN  \n",
       "23                   0.07526          NaN  \n",
       "24                   0.09564          NaN  \n",
       "25                   0.10590          NaN  \n",
       "26                   0.12750          NaN  \n",
       "27                   0.07421          NaN  \n",
       "28                   0.09876          NaN  \n",
       "29                   0.07919          NaN  \n",
       "..                       ...          ...  \n",
       "539                  0.10660          NaN  \n",
       "540                  0.08134          NaN  \n",
       "541                  0.10230          NaN  \n",
       "542                  0.06956          NaN  \n",
       "543                  0.06443          NaN  \n",
       "544                  0.08492          NaN  \n",
       "545                  0.06953          NaN  \n",
       "546                  0.07399          NaN  \n",
       "547                  0.09479          NaN  \n",
       "548                  0.07920          NaN  \n",
       "549                  0.07626          NaN  \n",
       "550                  0.06592          NaN  \n",
       "551                  0.08032          NaN  \n",
       "552                  0.06484          NaN  \n",
       "553                  0.07393          NaN  \n",
       "554                  0.07242          NaN  \n",
       "555                  0.08283          NaN  \n",
       "556                  0.06742          NaN  \n",
       "557                  0.06969          NaN  \n",
       "558                  0.08004          NaN  \n",
       "559                  0.08732          NaN  \n",
       "560                  0.08321          NaN  \n",
       "561                  0.05905          NaN  \n",
       "562                  0.14090          NaN  \n",
       "563                  0.09873          NaN  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv('data.csv')\n",
    "\n",
    "df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 32','id'], axis = 1 , inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis.replace({\"M\":1,\"B\":0},inplace=True)\n",
    "df.diagnosis.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df.corr(), cmap='YlGnBu', annot = True)\n",
    "plt.title(\"Correlation Map\", fontweight = \"bold\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'perimeter_mean', 'area_mean',\n",
       "       'concavity_mean', 'concave points_mean', 'radius_worst',\n",
       "       'perimeter_worst', 'area_worst', 'concavity_worst',\n",
       "       'concave points_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr[abs(corr['diagnosis']) > 0.60].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corr_matrix = df.corr()\n",
    "threshold = 0.60 \n",
    "filtre = np.abs(corr_matrix[\"diagnosis\"]) > threshold\n",
    "corr_features = corr_matrix.columns[filtre].tolist()\n",
    "sns.pairplot(df[corr_features], diag_kind = \"kde\", markers = \"+\", hue = \"diagnosis\", palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "5      1\n",
      "6      1\n",
      "7      1\n",
      "8      1\n",
      "9      1\n",
      "10     1\n",
      "11     1\n",
      "12     1\n",
      "13     1\n",
      "14     1\n",
      "15     1\n",
      "16     1\n",
      "17     1\n",
      "18     1\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     1\n",
      "24     1\n",
      "25     1\n",
      "26     1\n",
      "27     1\n",
      "28     1\n",
      "29     1\n",
      "      ..\n",
      "539    0\n",
      "540    0\n",
      "541    0\n",
      "542    0\n",
      "543    0\n",
      "544    0\n",
      "545    0\n",
      "546    0\n",
      "547    0\n",
      "548    0\n",
      "549    0\n",
      "550    0\n",
      "551    0\n",
      "552    0\n",
      "553    0\n",
      "554    0\n",
      "555    0\n",
      "556    0\n",
      "557    0\n",
      "558    0\n",
      "559    0\n",
      "560    0\n",
      "561    0\n",
      "562    1\n",
      "563    1\n",
      "564    1\n",
      "565    1\n",
      "566    1\n",
      "567    1\n",
      "568    0\n",
      "Name: diagnosis, Length: 569, dtype: int64\n",
      "     radius_mean  perimeter_mean  area_mean  concavity_mean  \\\n",
      "0         17.990          122.80     1001.0        0.300100   \n",
      "1         20.570          132.90     1326.0        0.086900   \n",
      "2         19.690          130.00     1203.0        0.197400   \n",
      "3         11.420           77.58      386.1        0.241400   \n",
      "4         20.290          135.10     1297.0        0.198000   \n",
      "5         12.450           82.57      477.1        0.157800   \n",
      "6         18.250          119.60     1040.0        0.112700   \n",
      "7         13.710           90.20      577.9        0.093660   \n",
      "8         13.000           87.50      519.8        0.185900   \n",
      "9         12.460           83.97      475.9        0.227300   \n",
      "10        16.020          102.70      797.8        0.032990   \n",
      "11        15.780          103.60      781.0        0.099540   \n",
      "12        19.170          132.40     1123.0        0.206500   \n",
      "13        15.850          103.70      782.7        0.099380   \n",
      "14        13.730           93.60      578.3        0.212800   \n",
      "15        14.540           96.73      658.8        0.163900   \n",
      "16        14.680           94.74      684.5        0.073950   \n",
      "17        16.130          108.10      798.8        0.172200   \n",
      "18        19.810          130.00     1260.0        0.147900   \n",
      "19        13.540           87.46      566.3        0.066640   \n",
      "20        13.080           85.63      520.0        0.045680   \n",
      "21         9.504           60.34      273.9        0.029560   \n",
      "22        15.340          102.50      704.4        0.207700   \n",
      "23        21.160          137.20     1404.0        0.109700   \n",
      "24        16.650          110.00      904.6        0.152500   \n",
      "25        17.140          116.00      912.7        0.222900   \n",
      "26        14.580           97.41      644.8        0.142500   \n",
      "27        18.610          122.10     1094.0        0.149000   \n",
      "28        15.300          102.40      732.4        0.168300   \n",
      "29        17.570          115.00      955.1        0.098750   \n",
      "..           ...             ...        ...             ...   \n",
      "539        7.691           48.34      170.4        0.092520   \n",
      "540       11.540           74.65      402.9        0.067370   \n",
      "541       14.470           95.81      656.4        0.100900   \n",
      "542       14.740           94.70      668.6        0.041050   \n",
      "543       13.210           84.88      538.4        0.029870   \n",
      "544       13.870           89.77      584.8        0.036880   \n",
      "545       13.620           87.19      573.2        0.029740   \n",
      "546       10.320           65.31      324.9        0.010120   \n",
      "547       10.260           65.85      320.8        0.043580   \n",
      "548        9.683           61.05      285.7        0.023370   \n",
      "549       10.820           68.89      361.6        0.015480   \n",
      "550       10.860           68.51      360.5        0.000000   \n",
      "551       11.130           71.49      378.4        0.048240   \n",
      "552       12.770           81.35      507.9        0.019970   \n",
      "553        9.333           59.01      264.0        0.039960   \n",
      "554       12.880           82.50      514.3        0.061950   \n",
      "555       10.290           65.67      321.4        0.059990   \n",
      "556       10.160           64.73      311.7        0.005025   \n",
      "557        9.423           59.26      271.3        0.000000   \n",
      "558       14.590           96.39      657.1        0.102900   \n",
      "559       11.510           74.52      403.5        0.111200   \n",
      "560       14.050           91.38      600.4        0.044620   \n",
      "561       11.200           70.67      386.0        0.000000   \n",
      "562       15.220          103.40      716.9        0.255000   \n",
      "563       20.920          143.00     1347.0        0.317400   \n",
      "564       21.560          142.00     1479.0        0.243900   \n",
      "565       20.130          131.20     1261.0        0.144000   \n",
      "566       16.600          108.30      858.1        0.092510   \n",
      "567       20.600          140.10     1265.0        0.351400   \n",
      "568        7.760           47.92      181.0        0.000000   \n",
      "\n",
      "     concave points_mean  radius_worst  perimeter_worst  area_worst  \\\n",
      "0               0.147100        25.380           184.60      2019.0   \n",
      "1               0.070170        24.990           158.80      1956.0   \n",
      "2               0.127900        23.570           152.50      1709.0   \n",
      "3               0.105200        14.910            98.87       567.7   \n",
      "4               0.104300        22.540           152.20      1575.0   \n",
      "5               0.080890        15.470           103.40       741.6   \n",
      "6               0.074000        22.880           153.20      1606.0   \n",
      "7               0.059850        17.060           110.60       897.0   \n",
      "8               0.093530        15.490           106.20       739.3   \n",
      "9               0.085430        15.090            97.65       711.4   \n",
      "10              0.033230        19.190           123.80      1150.0   \n",
      "11              0.066060        20.420           136.50      1299.0   \n",
      "12              0.111800        20.960           151.70      1332.0   \n",
      "13              0.053640        16.840           112.00       876.5   \n",
      "14              0.080250        15.030           108.80       697.7   \n",
      "15              0.073640        17.460           124.10       943.2   \n",
      "16              0.052590        19.070           123.40      1138.0   \n",
      "17              0.102800        20.960           136.80      1315.0   \n",
      "18              0.094980        27.320           186.80      2398.0   \n",
      "19              0.047810        15.110            99.70       711.2   \n",
      "20              0.031100        14.500            96.09       630.5   \n",
      "21              0.020760        10.230            65.13       314.9   \n",
      "22              0.097560        18.070           125.10       980.9   \n",
      "23              0.086320        29.170           188.00      2615.0   \n",
      "24              0.091700        26.460           177.00      2215.0   \n",
      "25              0.140100        22.250           152.40      1461.0   \n",
      "26              0.087830        17.620           122.40       896.9   \n",
      "27              0.077310        21.310           139.90      1403.0   \n",
      "28              0.087510        20.270           149.30      1269.0   \n",
      "29              0.079530        20.010           134.90      1227.0   \n",
      "..                   ...           ...              ...         ...   \n",
      "539             0.013640         8.678            54.49       223.6   \n",
      "540             0.025940        12.260            78.78       457.8   \n",
      "541             0.038900        16.220           113.50       808.9   \n",
      "542             0.030270        16.510           107.40       826.4   \n",
      "543             0.032750        14.370            92.48       629.6   \n",
      "544             0.023690        15.050            99.17       688.6   \n",
      "545             0.024430        15.350            97.58       729.8   \n",
      "546             0.005495        11.250            71.12       384.9   \n",
      "547             0.024380        10.830            71.08       357.4   \n",
      "548             0.009615        10.930            69.10       364.2   \n",
      "549             0.008160        13.030            83.90       505.6   \n",
      "550             0.000000        11.660            74.08       412.3   \n",
      "551             0.022570        12.020            77.80       436.6   \n",
      "552             0.014990        13.870            88.10       594.7   \n",
      "553             0.012820         9.845            62.86       295.8   \n",
      "554             0.023430        13.890            88.84       595.7   \n",
      "555             0.027380        10.840            69.57       357.6   \n",
      "556             0.011160        10.650            67.88       347.3   \n",
      "557             0.000000        10.490            66.50       330.6   \n",
      "558             0.037360        15.480           105.90       733.5   \n",
      "559             0.041050        12.480            82.28       474.2   \n",
      "560             0.043040        15.300           100.20       706.7   \n",
      "561             0.000000        11.920            75.19       439.6   \n",
      "562             0.094290        17.520           128.70       915.0   \n",
      "563             0.147400        24.290           179.10      1819.0   \n",
      "564             0.138900        25.450           166.10      2027.0   \n",
      "565             0.097910        23.690           155.00      1731.0   \n",
      "566             0.053020        18.980           126.70      1124.0   \n",
      "567             0.152000        25.740           184.60      1821.0   \n",
      "568             0.000000         9.456            59.16       268.6   \n",
      "\n",
      "     concavity_worst  concave points_worst  \n",
      "0            0.71190               0.26540  \n",
      "1            0.24160               0.18600  \n",
      "2            0.45040               0.24300  \n",
      "3            0.68690               0.25750  \n",
      "4            0.40000               0.16250  \n",
      "5            0.53550               0.17410  \n",
      "6            0.37840               0.19320  \n",
      "7            0.26780               0.15560  \n",
      "8            0.53900               0.20600  \n",
      "9            1.10500               0.22100  \n",
      "10           0.14590               0.09975  \n",
      "11           0.39650               0.18100  \n",
      "12           0.36390               0.17670  \n",
      "13           0.23220               0.11190  \n",
      "14           0.69430               0.22080  \n",
      "15           0.70260               0.17120  \n",
      "16           0.29140               0.16090  \n",
      "17           0.47840               0.20730  \n",
      "18           0.53720               0.23880  \n",
      "19           0.23900               0.12880  \n",
      "20           0.18900               0.07283  \n",
      "21           0.08867               0.06227  \n",
      "22           0.63050               0.23930  \n",
      "23           0.31550               0.20090  \n",
      "24           0.46950               0.20950  \n",
      "25           0.38530               0.25500  \n",
      "26           0.55390               0.27010  \n",
      "27           0.34460               0.14900  \n",
      "28           0.63350               0.20240  \n",
      "29           0.24890               0.14560  \n",
      "..               ...                   ...  \n",
      "539          0.33930               0.05000  \n",
      "540          0.17970               0.06918  \n",
      "541          0.40400               0.12050  \n",
      "542          0.16110               0.10950  \n",
      "543          0.10620               0.07958  \n",
      "544          0.13770               0.06845  \n",
      "545          0.10490               0.07174  \n",
      "546          0.04384               0.02381  \n",
      "547          0.17830               0.08333  \n",
      "548          0.09350               0.03846  \n",
      "549          0.06194               0.03264  \n",
      "550          0.00000               0.00000  \n",
      "551          0.15640               0.06413  \n",
      "552          0.08653               0.06498  \n",
      "553          0.07993               0.02564  \n",
      "554          0.24390               0.06493  \n",
      "555          0.20000               0.09127  \n",
      "556          0.01005               0.02232  \n",
      "557          0.00000               0.00000  \n",
      "558          0.36620               0.11050  \n",
      "559          0.36300               0.09653  \n",
      "560          0.13260               0.10480  \n",
      "561          0.00000               0.00000  \n",
      "562          1.17000               0.23560  \n",
      "563          0.65990               0.25420  \n",
      "564          0.41070               0.22160  \n",
      "565          0.32150               0.16280  \n",
      "566          0.34030               0.14180  \n",
      "567          0.93870               0.26500  \n",
      "568          0.00000               0.00000  \n",
      "\n",
      "[569 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "y=df.iloc[:,0]\n",
    "X=df.iloc[:,[1,3,4,7,8,21,23,24,27,28]]\n",
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# split the data to X and y before Local Outlier Factorization\n",
    "\n",
    "y=df[\"diagnosis\"]\n",
    "X=df.drop([\"diagnosis\"],axis=1)\n",
    "columns= df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lof= LocalOutlierFactor()\n",
    "y_pred=lof.fit_predict(X)\n",
    "y_pred[0:11]\n",
    "#  1 = inlier\n",
    "# -1 = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_score= lof.negative_outlier_factor_\n",
    "outlier_score= pd.DataFrame()\n",
    "outlier_score[\"score\"]=x_score\n",
    "\n",
    "lofthreshold= -2.5\n",
    "loffilter= outlier_score[\"score\"]< lofthreshold\n",
    "outlier_index= outlier_score[loffilter].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X.drop(outlier_index)\n",
    "y= y.drop(outlier_index).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,stratify=y,random_state=42)\n",
    "\n",
    "# Dont fit the scaler while standardizate X_test !\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9748110831234257\n",
      "- MCC: 0.9462780027577381\n",
      "- F1 score: 0.9746571285078596\n",
      "Confusion matrix for training set\n",
      " [[249   1]\n",
      " [  9 138]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9649122807017544\n",
      "- MCC: 0.9263533510348259\n",
      "- F1 score: 0.9645279368316471\n",
      "Confusion matrix for testing set\n",
      " [[107   0]\n",
      " [  6  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "#X_train, X_test\n",
    "\n",
    "knn = KNeighborsClassifier(5) # Define classifier\n",
    "knn.fit(X_train, y_train) # Train model\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "knn_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "knn_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "knn_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "knn_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "knn_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "knn_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % knn_train_accuracy)\n",
    "print('- MCC: %s' % knn_train_mcc)\n",
    "print('- F1 score: %s' % knn_train_f1)\n",
    "print(\"Confusion matrix for training set\\n\",confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % knn_test_accuracy)\n",
    "print('- MCC: %s' % knn_test_mcc)\n",
    "print('- F1 score: %s' % knn_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9899244332493703\n",
      "- MCC: 0.9785037567705266\n",
      "- F1 score: 0.9898949289898651\n",
      "Confusion matrix for training set\n",
      " [[250   0]\n",
      " [  4 143]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9707602339181286\n",
      "- MCC: 0.9384667634346081\n",
      "- F1 score: 0.9704997170135123\n",
      "Confusion matrix for testing set\n",
      " [[107   0]\n",
      " [  5  59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "svm_rbf = SVC(kernel='linear', C=1)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = svm_rbf.predict(X_train)\n",
    "y_test_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "svm_rbf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "svm_rbf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "svm_rbf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "svm_rbf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "svm_rbf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "svm_rbf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % svm_rbf_train_accuracy)\n",
    "print('- MCC: %s' % svm_rbf_train_mcc)\n",
    "print('- F1 score: %s' % svm_rbf_train_f1)\n",
    "print(\"Confusion matrix for training set\\n\",confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print('----------------------------------') \n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % svm_rbf_test_accuracy)\n",
    "print('- MCC: %s' % svm_rbf_test_mcc)\n",
    "print('- F1 score: %s' % svm_rbf_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "Confusion matrix for training set\n",
      " [[250   0]\n",
      " [  0 147]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8888888888888888\n",
      "- MCC: 0.7610661249994807\n",
      "- F1 score: 0.8883236047107015\n",
      "Confusion matrix for testing set\n",
      " [[99  8]\n",
      " [11 53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=10) # Define classifier\n",
    "dt.fit(X_train, y_train) # Train model\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "dt_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "dt_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "dt_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "dt_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "dt_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "dt_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % dt_train_accuracy)\n",
    "print('- MCC: %s' % dt_train_mcc)\n",
    "print('- F1 score: %s' % dt_train_f1)\n",
    "print(\"Confusion matrix for training set\\n\",confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % dt_test_accuracy)\n",
    "print('- MCC: %s' % dt_test_mcc)\n",
    "print('- F1 score: %s' % dt_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "Confusion matrix for training set\n",
      " [[250   0]\n",
      " [  0 147]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9649122807017544\n",
      "- MCC: 0.9263533510348259\n",
      "- F1 score: 0.9645279368316471\n",
      "Confusion matrix for testing set\n",
      " [[107   0]\n",
      " [  6  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=40,random_state=0) # Define classifier\n",
    "rf.fit(X_train, y_train) # Train model\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "rf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "rf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "rf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "rf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "rf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "rf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % rf_train_accuracy)\n",
    "print('- MCC: %s' % rf_train_mcc)\n",
    "print('- F1 score: %s' % rf_train_f1)\n",
    "print(\"Confusion matrix for training set\\n\",confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % rf_test_accuracy)\n",
    "print('- MCC: %s' % rf_test_mcc)\n",
    "print('- F1 score: %s' % rf_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9924433249370277\n",
      "- MCC: 0.9838577759288312\n",
      "- F1 score: 0.9924269078200045\n",
      "Confusion matrix for training set\n",
      " [[250   0]\n",
      " [  3 144]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9707602339181286\n",
      "- MCC: 0.9384667634346081\n",
      "- F1 score: 0.9704997170135123\n",
      "Confusion matrix for testing set\n",
      " [[107   0]\n",
      " [  5  59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "mlp = MLPClassifier(alpha=1, max_iter=500,random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "mlp_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "mlp_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "mlp_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "mlp_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "mlp_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "mlp_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % mlp_train_accuracy)\n",
    "print('- MCC: %s' % mlp_train_mcc)\n",
    "print('- F1 score: %s' % mlp_train_f1)\n",
    "print(\"Confusion matrix for training set\\n\",confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % mlp_test_accuracy)\n",
    "print('- MCC: %s' % mlp_test_mcc)\n",
    "print('- F1 score: %s' % mlp_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Test set for gradient boosting\n",
      "- Accuracy: 0.9473684210526315\n",
      "- MCC: 0.8871974560470782\n",
      "- F1 score: 0.9471006548629638\n",
      "Confusion matrix for testing set\n",
      " [[104   3]\n",
      " [  6  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "NB= BernoulliNB()\n",
    "NB.fit(X_train, y_train)\n",
    "y_test_pred_NB = NB.predict(X_test)\n",
    "\n",
    "NB_test_accuracy = accuracy_score(y_test, y_test_pred_NB) # Calculate Accuracy\n",
    "NB_test_mcc = matthews_corrcoef(y_test, y_test_pred_NB) # Calculate MCC\n",
    "NB_test_f1 = f1_score(y_test, y_test_pred_NB, average='weighted') # Calculat\n",
    "print('Model performance for Test set for gradient boosting')\n",
    "print('- Accuracy: %s' % NB_test_accuracy)\n",
    "print('- MCC: %s' % NB_test_mcc)\n",
    "print('- F1 score: %s' % NB_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred_NB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Test set for gradient boosting\n",
      "- Accuracy: 0.9590643274853801\n",
      "- MCC: 0.9130465485530433\n",
      "- F1 score: 0.9586996038189173\n",
      "Confusion matrix for testing set\n",
      " [[106   1]\n",
      " [  6  58]]\n",
      "Model performance for Test set ada boosting\n",
      "- Accuracy: 0.9649122807017544\n",
      "- MCC: 0.9263533510348259\n",
      "- F1 score: 0.9645279368316471\n",
      "Confusion matrix for testing set\n",
      " [[107   0]\n",
      " [  6  58]]\n"
     ]
    }
   ],
   "source": [
    "gb=GradientBoostingClassifier(random_state=20)\n",
    "ab=AdaBoostClassifier()\n",
    "#xgb=XGBClassifier(random_state=0,booster=\"gbtree\")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "ab.fit(X_train, y_train)\n",
    "#xgb.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred_gb = gb.predict(X_test)\n",
    "y_test_pred_ab = ab.predict(X_test)\n",
    "#y_test_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "gb_test_accuracy = accuracy_score(y_test, y_test_pred_gb) # Calculate Accuracy\n",
    "gb_test_mcc = matthews_corrcoef(y_test, y_test_pred_gb) # Calculate MCC\n",
    "gb_test_f1 = f1_score(y_test, y_test_pred_gb, average='weighted') # Calculate F1-score\n",
    "\n",
    "ab_test_accuracy = accuracy_score(y_test, y_test_pred_ab) # Calculate Accuracy\n",
    "ab_test_mcc = matthews_corrcoef(y_test, y_test_pred_ab) # Calculate MCC\n",
    "ab_test_f1 = f1_score(y_test, y_test_pred_ab, average='weighted') # Calculate F1-score\n",
    "\n",
    "#xgb_test_accuracy = accuracy_score(y_test, y_test_pred_xgb) # Calculate Accuracy\n",
    "#xgb_test_mcc = matthews_corrcoef(y_test, y_test_pred_xgb) # Calculate MCC\n",
    "#xgb_test_f1 = f1_score(y_test, y_test_pred_xgb, average='weighted') # Calculate F1-score\n",
    "\n",
    "\n",
    "print('Model performance for Test set for gradient boosting')\n",
    "print('- Accuracy: %s' % gb_test_accuracy)\n",
    "print('- MCC: %s' % gb_test_mcc)\n",
    "print('- F1 score: %s' % gb_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred_gb))\n",
    "\n",
    "print('Model performance for Test set ada boosting')\n",
    "print('- Accuracy: %s' % ab_test_accuracy)\n",
    "print('- MCC: %s' % ab_test_mcc)\n",
    "print('- F1 score: %s' % ab_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred_ab))\n",
    "\n",
    "#print('Model performance for Test set xg boosting')\n",
    "#print('- Accuracy: %s' % xgb_test_accuracy)\n",
    "#print('- MCC: %s' % xgb_test_mcc)\n",
    "#print('- F1 score: %s' % xgb_test_f1)\n",
    "#print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9924433249370277\n",
      "- MCC: 0.983787570003184\n",
      "- F1 score: 0.9924379711789703\n",
      "Confusion matrix for training set\n",
      " [[249   1]\n",
      " [  2 145]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9941520467836257\n",
      "- MCC: 0.987552741207611\n",
      "- F1 score: 0.9941426232369669\n",
      "Confusion matrix for testing set\n",
      " [[107   0]\n",
      " [  1  63]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define estimators\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "estimator_list = [\n",
    "    \n",
    "    ('svm',svm_rbf),\n",
    "   \n",
    "    ('knn',knn),\n",
    "    ('rf',rf),\n",
    "    ('mlp',mlp) ]\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Build stack model\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=estimator_list,cv=5, final_estimator=GaussianNB()\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = stack_model.predict(X_train)\n",
    "y_test_pred = stack_model.predict(X_test)\n",
    "end = time.time()\n",
    "# Training set model performance\n",
    "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set model performance\n",
    "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
    "print('- MCC: %s' % stack_model_train_mcc)\n",
    "print('- F1 score: %s' % stack_model_train_f1)\n",
    "print(\"Confusion matrix for training set\\n\",confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
    "print('- MCC: %s' % stack_model_test_mcc)\n",
    "print('- F1 score: %s' % stack_model_test_f1)\n",
    "print(\"Confusion matrix for testing set\\n\",confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.106712818145752\n"
     ]
    }
   ],
   "source": [
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_list = {'knn':knn_test_accuracy,\n",
    "'svm': svm_rbf_test_accuracy,\n",
    "'dt': dt_test_accuracy,\n",
    "'rf': rf_test_accuracy,\n",
    "'mlp': mlp_test_accuracy,\n",
    "'stack': stack_model_test_accuracy}\n",
    "\n",
    "mcc_test_list = {'knn':knn_test_mcc,\n",
    "'svm': svm_rbf_test_mcc,\n",
    "'dt': dt_test_mcc,\n",
    "'rf': rf_test_mcc,\n",
    "'mlp': mlp_test_mcc,\n",
    "'stack': stack_model_test_mcc}\n",
    "\n",
    "f1_test_list = {'knn':knn_test_f1,\n",
    "'svm': svm_rbf_test_f1,\n",
    "'dt': dt_test_f1,\n",
    "'rf': rf_test_f1,\n",
    "'mlp': mlp_test_f1,\n",
    "'stack': stack_model_test_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "acc_df = pd.DataFrame.from_dict(acc_test_list, orient='index', columns=['Accuracy'])\n",
    "mcc_df = pd.DataFrame.from_dict(mcc_test_list, orient='index', columns=['MCC'])\n",
    "f1_df = pd.DataFrame.from_dict(f1_test_list, orient='index', columns=['F1'])\n",
    "df = pd.concat([acc_df, mcc_df, f1_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.926353</td>\n",
       "      <td>0.964528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.970760</td>\n",
       "      <td>0.938467</td>\n",
       "      <td>0.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.761066</td>\n",
       "      <td>0.888324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.926353</td>\n",
       "      <td>0.964528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.970760</td>\n",
       "      <td>0.938467</td>\n",
       "      <td>0.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.987553</td>\n",
       "      <td>0.994143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       MCC        F1\n",
       "knn    0.964912  0.926353  0.964528\n",
       "svm    0.970760  0.938467  0.970500\n",
       "dt     0.888889  0.761066  0.888324\n",
       "rf     0.964912  0.926353  0.964528\n",
       "mlp    0.970760  0.938467  0.970500\n",
       "stack  0.994152  0.987553  0.994143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "acc_df = pd.DataFrame.from_dict(acc_test_list, orient='index', columns=['Accuracy']) \n",
    "mcc_df = pd.DataFrame.from_dict(mcc_test_list, orient='index', columns=['MCC']) \n",
    "f1_df = pd.DataFrame.from_dict(f1_test_list, orient='index', columns=['F1']) \n",
    "df = pd.concat([acc_df, mcc_df, f1_df], axis=1) \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
